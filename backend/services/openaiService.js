import OpenAI from 'openai';
import dotenv from 'dotenv';
import personalizationService from './personalizationService.js';

dotenv.config();

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

const RESPONSE_LENGTHS = {
  corto: 50,    // Respuestas r치pidas y conversacionales
  medio: 150,   // Respuestas con algo m치s de contexto
  largo: 300    // Respuestas elaboradas para temas importantes
};

const determineResponseLength = (message, context) => {
  // Palabras clave que indican necesidad de respuesta elaborada
  const longResponseTriggers = [
    'explica', 'expl칤came', 'por qu칠', 'ay칰dame a entender',
    'necesito ayuda con', 'c칩mo puedo', 'qu칠 opinas sobre'
  ];

  // Palabras clave que indican respuesta corta
  const shortResponseTriggers = [
    'ok', 's칤', 'no', 'bien', 'gracias', 'entiendo',
    'claro', 'vale', '游녨', '游땕'
  ];

  const messageContent = message.content.toLowerCase();

  // Si el mensaje del usuario es corto y simple, responder de forma similar
  if (messageContent.split(' ').length <= 4 || 
      shortResponseTriggers.some(trigger => messageContent.includes(trigger))) {
    return 'corto';
  }

  // Si el mensaje indica necesidad de explicaci칩n o ayuda espec칤fica
  if (longResponseTriggers.some(trigger => messageContent.includes(trigger))) {
    return 'largo';
  }

  // Por defecto, usar respuestas medias para mantener la conversaci칩n fluida
  return 'medio';
};

const analyzeMessageContext = async (message, conversationHistory) => {
  try {
    const contextPrompt = {
      role: 'system',
      content: `Analiza el siguiente mensaje y su contexto. Responde SOLO con un objeto JSON v치lido que contenga:
      {
        "emotionalContext": {
          "mainEmotion": string,
          "intensity": number (1-10),
          "sentiment": "positive" | "neutral" | "negative"
        },
        "topics": string[],
        "intent": string,
        "urgency": number (1-5)
      }
      
      NO incluyas comentarios, explicaciones o texto adicional fuera del JSON.
      NO uses caracteres especiales o saltos de l칤nea dentro de los valores string.
      ASEG칔RATE de que el JSON sea v치lido y parseable.`
    };

    const completion = await openai.chat.completions.create({
      model: 'gpt-4-turbo-preview',
      messages: [
        contextPrompt,
        ...conversationHistory.slice(-3).map(msg => ({
          role: msg.role,
          content: msg.content
        })),
        {
          role: 'user',
          content: message.content
        }
      ],
      temperature: 0.3, // Temperatura baja para respuestas m치s consistentes
      max_tokens: 150,
      response_format: { type: "json_object" } // Forzar formato JSON
    });

    let contextData;
    try {
      contextData = JSON.parse(completion.choices[0].message.content);
    } catch (parseError) {
      console.error('Error parseando JSON:', parseError);
      // Retornar un contexto por defecto si hay error de parsing
      return {
        emotionalContext: {
          mainEmotion: 'neutral',
          intensity: 5,
          sentiment: 'neutral'
        },
        topics: ['general'],
        intent: 'conversation',
        urgency: 1
      };
    }

    // Validar y sanitizar el objeto JSON
    return {
      emotionalContext: {
        mainEmotion: String(contextData.emotionalContext?.mainEmotion || 'neutral'),
        intensity: Number(contextData.emotionalContext?.intensity || 5),
        sentiment: String(contextData.emotionalContext?.sentiment || 'neutral')
      },
      topics: Array.isArray(contextData.topics) ? 
        contextData.topics.map(topic => String(topic)) : ['general'],
      intent: String(contextData.intent || 'conversation'),
      urgency: Number(contextData.urgency || 1)
    };

  } catch (error) {
    console.error('Error en an치lisis de contexto:', error);
    // Retornar un contexto por defecto si hay error general
    return {
      emotionalContext: {
        mainEmotion: 'neutral',
        intensity: 5,
        sentiment: 'neutral'
      },
      topics: ['general'],
      intent: 'conversation',
      urgency: 1
    };
  }
};

// Funci칩n auxiliar para sanitizar strings JSON
const sanitizeJsonString = (str) => {
  return str
    .replace(/[\n\r\t]/g, ' ') // Reemplazar saltos de l칤nea y tabs con espacios
    .replace(/\s+/g, ' ')      // Reducir m칰ltiples espacios a uno solo
    .trim();                   // Eliminar espacios al inicio y final
};

const generateAIResponse = async (message, conversationHistory, userId) => {
  try {
    const personalizedPrompt = await personalizationService.getPersonalizedPrompt(userId);
    const context = await analyzeMessageContext(message, conversationHistory);
    
    // Determinar la longitud apropiada de la respuesta
    const responseLength = determineResponseLength(message, context);

    const enrichedPrompt = {
      role: 'system',
      content: `Eres Anto, un asistente conversacional amigable y emp치tico. 

      ESTILO DE CONVERSACI칍N:
      - Mant칠n un tono casual y natural, como en una conversaci칩n por WhatsApp
      - Usa respuestas cortas y directas cuando sea posible
      - Divide mensajes largos en varios m치s cortos si es necesario
      - Usa emojis ocasionalmente para dar calidez 游땕
      - Evita respuestas demasiado formales o acad칠micas
      
      LONGITUD DE RESPUESTA: ${responseLength}
      - corto: respuesta concisa y directa
      - medio: respuesta con contexto pero manteniendo la fluidez
      - largo: respuesta detallada para temas importantes
      
      CONTEXTO TEMPORAL:
      - Momento del d칤a: ${personalizedPrompt.timeContext || 'afternoon'}
      - Saludo: ${personalizedPrompt.greeting || 'Hola'}
      
      CONTEXTO EMOCIONAL:
      - Emoci칩n actual: ${context?.emotionalContext?.mainEmotion || 'neutral'}
      
      INSTRUCCIONES ESPEC칈FICAS:
      1. Responde siempre en espa침ol
      2. Mant칠n la conversaci칩n fluida y natural
      3. Si el tema es complejo, sugiere dividirlo en partes m치s manejables
      4. Adapta tu estilo al contexto emocional del usuario`
    };

    const completion = await openai.chat.completions.create({
      model: 'gpt-4-turbo-preview',
      messages: [
        enrichedPrompt,
        ...conversationHistory.map(msg => ({
          role: msg.role,
          content: msg.content
        })),
        {
          role: 'user',
          content: message.content
        }
      ],
      temperature: 0.7,
      max_tokens: RESPONSE_LENGTHS[responseLength],
      presence_penalty: 0.6,  // Favorece respuestas m치s variadas
      frequency_penalty: 0.5  // Evita repeticiones
    });

    // Actualizar el patr칩n de interacci칩n
    await personalizationService.updateInteractionPattern(
      userId,
      context?.emotionalContext?.mainEmotion || 'neutral',
      context?.topics?.[0] || 'general'
    );

    return {
      content: completion.choices[0].message.content,
      context: context || { 
        emotionalContext: { mainEmotion: 'neutral', intensity: 5 }, 
        topics: ['general'] 
      }
    };
  } catch (error) {
    console.error('Error generando respuesta:', error);
    throw error;
  }
};

export default {
  analyzeMessageContext,
  generateAIResponse
}; 